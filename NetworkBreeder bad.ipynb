{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: /Users/ian/.keras/datasets/iris_training.csv\n",
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n",
      "OrderedDict([('sepal_length', <tf.Tensor: id=341, shape=(32,), dtype=float32, numpy=\n",
      "array([5.5, 6.1, 4.4, 6.4, 5.7, 6.5, 7.7, 6.4, 6. , 6.2, 4.9, 6.4, 5.4,\n",
      "       5. , 6. , 6.5, 7.2, 5. , 4.7, 4.6, 5.7, 5.1, 5.3, 5.8, 7.2, 5.8,\n",
      "       4.4, 6.8, 5.2, 6.2, 4.7, 7.7], dtype=float32)>), ('sepal_width', <tf.Tensor: id=342, shape=(32,), dtype=float32, numpy=\n",
      "array([3.5, 2.8, 2.9, 2.8, 4.4, 2.8, 2.8, 3.2, 2.7, 2.8, 2.5, 2.8, 3.9,\n",
      "       3.4, 2.9, 3. , 3.6, 3.6, 3.2, 3.6, 3. , 2.5, 3.7, 2.7, 3. , 2.8,\n",
      "       3. , 2.8, 3.5, 3.4, 3.2, 3.8], dtype=float32)>), ('petal_length', <tf.Tensor: id=339, shape=(32,), dtype=float32, numpy=\n",
      "array([1.3, 4. , 1.4, 5.6, 1.5, 4.6, 6.7, 4.5, 5.1, 4.8, 4.5, 5.6, 1.3,\n",
      "       1.5, 4.5, 5.5, 6.1, 1.4, 1.3, 1. , 4.2, 3. , 1.5, 5.1, 5.8, 5.1,\n",
      "       1.3, 4.8, 1.5, 5.4, 1.6, 6.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=340, shape=(32,), dtype=float32, numpy=\n",
      "array([0.2, 1.3, 0.2, 2.2, 0.4, 1.5, 2. , 1.5, 1.6, 1.8, 1.7, 2.1, 0.4,\n",
      "       0.2, 1.5, 1.8, 2.5, 0.2, 0.2, 0.2, 1.2, 1.1, 0.2, 1.9, 1.6, 2.4,\n",
      "       0.2, 1.4, 0.2, 2.3, 0.2, 2.2], dtype=float32)>)])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "train_dataset_fp = keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n",
    "# column order in CSV file\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)\n",
    "plt.scatter(features['petal_length'],\n",
    "            features['sepal_length'],\n",
    "            c=labels,\n",
    "            cmap='viridis')\n",
    "\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'odict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b5fc362650a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'odict_values' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "inputTensor = keras.layers.Input(input_shape)\n",
    "x = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer sequential_5 was called with an input that isn't a symbolic tensor. Received type: <class 'collections.OrderedDict'>. Full input: [OrderedDict([('sepal_length', <tf.Tensor: id=341, shape=(32,), dtype=float32, numpy=\narray([5.5, 6.1, 4.4, 6.4, 5.7, 6.5, 7.7, 6.4, 6. , 6.2, 4.9, 6.4, 5.4,\n       5. , 6. , 6.5, 7.2, 5. , 4.7, 4.6, 5.7, 5.1, 5.3, 5.8, 7.2, 5.8,\n       4.4, 6.8, 5.2, 6.2, 4.7, 7.7], dtype=float32)>), ('sepal_width', <tf.Tensor: id=342, shape=(32,), dtype=float32, numpy=\narray([3.5, 2.8, 2.9, 2.8, 4.4, 2.8, 2.8, 3.2, 2.7, 2.8, 2.5, 2.8, 3.9,\n       3.4, 2.9, 3. , 3.6, 3.6, 3.2, 3.6, 3. , 2.5, 3.7, 2.7, 3. , 2.8,\n       3. , 2.8, 3.5, 3.4, 3.2, 3.8], dtype=float32)>), ('petal_length', <tf.Tensor: id=339, shape=(32,), dtype=float32, numpy=\narray([1.3, 4. , 1.4, 5.6, 1.5, 4.6, 6.7, 4.5, 5.1, 4.8, 4.5, 5.6, 1.3,\n       1.5, 4.5, 5.5, 6.1, 1.4, 1.3, 1. , 4.2, 3. , 1.5, 5.1, 5.8, 5.1,\n       1.3, 4.8, 1.5, 5.4, 1.6, 6.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=340, shape=(32,), dtype=float32, numpy=\narray([0.2, 1.3, 0.2, 2.2, 0.4, 1.5, 2. , 1.5, 1.6, 1.8, 1.7, 2.1, 0.4,\n       0.2, 1.5, 1.8, 2.5, 0.2, 0.2, 0.2, 1.2, 1.1, 0.2, 1.9, 1.6, 2.4,\n       0.2, 1.4, 0.2, 2.3, 0.2, 2.2], dtype=float32)>)])]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 697\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'collections.OrderedDict'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3c164a120d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   ]))\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer sequential_5 was called with an input that isn't a symbolic tensor. Received type: <class 'collections.OrderedDict'>. Full input: [OrderedDict([('sepal_length', <tf.Tensor: id=341, shape=(32,), dtype=float32, numpy=\narray([5.5, 6.1, 4.4, 6.4, 5.7, 6.5, 7.7, 6.4, 6. , 6.2, 4.9, 6.4, 5.4,\n       5. , 6. , 6.5, 7.2, 5. , 4.7, 4.6, 5.7, 5.1, 5.3, 5.8, 7.2, 5.8,\n       4.4, 6.8, 5.2, 6.2, 4.7, 7.7], dtype=float32)>), ('sepal_width', <tf.Tensor: id=342, shape=(32,), dtype=float32, numpy=\narray([3.5, 2.8, 2.9, 2.8, 4.4, 2.8, 2.8, 3.2, 2.7, 2.8, 2.5, 2.8, 3.9,\n       3.4, 2.9, 3. , 3.6, 3.6, 3.2, 3.6, 3. , 2.5, 3.7, 2.7, 3. , 2.8,\n       3. , 2.8, 3.5, 3.4, 3.2, 3.8], dtype=float32)>), ('petal_length', <tf.Tensor: id=339, shape=(32,), dtype=float32, numpy=\narray([1.3, 4. , 1.4, 5.6, 1.5, 4.6, 6.7, 4.5, 5.1, 4.8, 4.5, 5.6, 1.3,\n       1.5, 4.5, 5.5, 6.1, 1.4, 1.3, 1. , 4.2, 3. , 1.5, 5.1, 5.8, 5.1,\n       1.3, 4.8, 1.5, 5.4, 1.6, 6.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=340, shape=(32,), dtype=float32, numpy=\narray([0.2, 1.3, 0.2, 2.2, 0.4, 1.5, 2. , 1.5, 1.6, 1.8, 1.7, 2.1, 0.4,\n       0.2, 1.5, 1.8, 2.5, 0.2, 0.2, 0.2, 1.2, 1.1, 0.2, 1.9, 1.6, 2.4,\n       0.2, 1.4, 0.2, 2.3, 0.2, 2.2], dtype=float32)>)])]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "\n",
    "n_models = 2\n",
    "models = []\n",
    "for _ in range(n_models):\n",
    "    models.append(keras.Sequential([\n",
    "        keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "        keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(3)\n",
    "  ]))\n",
    "    \n",
    "# predictions = models(features)\n",
    "# predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer sequential_6 was called with an input that isn't a symbolic tensor. Received type: <class 'collections.OrderedDict'>. Full input: [OrderedDict([('sepal_length', <tf.Tensor: id=341, shape=(32,), dtype=float32, numpy=\narray([5.5, 6.1, 4.4, 6.4, 5.7, 6.5, 7.7, 6.4, 6. , 6.2, 4.9, 6.4, 5.4,\n       5. , 6. , 6.5, 7.2, 5. , 4.7, 4.6, 5.7, 5.1, 5.3, 5.8, 7.2, 5.8,\n       4.4, 6.8, 5.2, 6.2, 4.7, 7.7], dtype=float32)>), ('sepal_width', <tf.Tensor: id=342, shape=(32,), dtype=float32, numpy=\narray([3.5, 2.8, 2.9, 2.8, 4.4, 2.8, 2.8, 3.2, 2.7, 2.8, 2.5, 2.8, 3.9,\n       3.4, 2.9, 3. , 3.6, 3.6, 3.2, 3.6, 3. , 2.5, 3.7, 2.7, 3. , 2.8,\n       3. , 2.8, 3.5, 3.4, 3.2, 3.8], dtype=float32)>), ('petal_length', <tf.Tensor: id=339, shape=(32,), dtype=float32, numpy=\narray([1.3, 4. , 1.4, 5.6, 1.5, 4.6, 6.7, 4.5, 5.1, 4.8, 4.5, 5.6, 1.3,\n       1.5, 4.5, 5.5, 6.1, 1.4, 1.3, 1. , 4.2, 3. , 1.5, 5.1, 5.8, 5.1,\n       1.3, 4.8, 1.5, 5.4, 1.6, 6.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=340, shape=(32,), dtype=float32, numpy=\narray([0.2, 1.3, 0.2, 2.2, 0.4, 1.5, 2. , 1.5, 1.6, 1.8, 1.7, 2.1, 0.4,\n       0.2, 1.5, 1.8, 2.5, 0.2, 0.2, 0.2, 1.2, 1.1, 0.2, 1.9, 1.6, 2.4,\n       0.2, 1.4, 0.2, 2.3, 0.2, 2.2], dtype=float32)>)])]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 697\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'collections.OrderedDict'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-515811973fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-515811973fd6>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, inputs, targets)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-515811973fd6>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer sequential_6 was called with an input that isn't a symbolic tensor. Received type: <class 'collections.OrderedDict'>. Full input: [OrderedDict([('sepal_length', <tf.Tensor: id=341, shape=(32,), dtype=float32, numpy=\narray([5.5, 6.1, 4.4, 6.4, 5.7, 6.5, 7.7, 6.4, 6. , 6.2, 4.9, 6.4, 5.4,\n       5. , 6. , 6.5, 7.2, 5. , 4.7, 4.6, 5.7, 5.1, 5.3, 5.8, 7.2, 5.8,\n       4.4, 6.8, 5.2, 6.2, 4.7, 7.7], dtype=float32)>), ('sepal_width', <tf.Tensor: id=342, shape=(32,), dtype=float32, numpy=\narray([3.5, 2.8, 2.9, 2.8, 4.4, 2.8, 2.8, 3.2, 2.7, 2.8, 2.5, 2.8, 3.9,\n       3.4, 2.9, 3. , 3.6, 3.6, 3.2, 3.6, 3. , 2.5, 3.7, 2.7, 3. , 2.8,\n       3. , 2.8, 3.5, 3.4, 3.2, 3.8], dtype=float32)>), ('petal_length', <tf.Tensor: id=339, shape=(32,), dtype=float32, numpy=\narray([1.3, 4. , 1.4, 5.6, 1.5, 4.6, 6.7, 4.5, 5.1, 4.8, 4.5, 5.6, 1.3,\n       1.5, 4.5, 5.5, 6.1, 1.4, 1.3, 1. , 4.2, 3. , 1.5, 5.1, 5.8, 5.1,\n       1.3, 4.8, 1.5, 5.4, 1.6, 6.7], dtype=float32)>), ('petal_width', <tf.Tensor: id=340, shape=(32,), dtype=float32, numpy=\narray([0.2, 1.3, 0.2, 2.2, 0.4, 1.5, 2. , 1.5, 1.6, 1.8, 1.7, 2.1, 0.4,\n       0.2, 1.5, 1.8, 2.5, 0.2, 0.2, 0.2, 1.2, 1.1, 0.2, 1.9, 1.6, 2.4,\n       0.2, 1.4, 0.2, 2.3, 0.2, 2.2], dtype=float32)>)])]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "# l = loss(models[0], features, labels)\n",
    "# print(\"Loss test: {}\".format(l))\n",
    "\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_value, grads = grad(models[0], features, labels)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, models[0].trainable_variables))\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss(models[0], features, labels).numpy()))\n",
    "'''\n",
    "## Note: Rerunning this cell uses the same model variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3065df70b89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# l = loss(model, features, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "# model.compile(\n",
    "#  optimizer = \"adam\",\n",
    "#  loss = \"binary_crossentropy\",\n",
    "#  metrics = [\"accuracy\"]\n",
    "# )\n",
    "# model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# # l = loss(model, features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5b8cfe9fa797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#     for model in models:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss_value_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = keras.metrics.Mean()\n",
    "    epoch_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    # Training loop - using batches of 32\n",
    "    for x, y in train_dataset:\n",
    "        # Optimize the model\n",
    "        loss_value = tf.Variable((x.shape))\n",
    "        #     for model in models:\n",
    "        loss_value_part, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        epoch_accuracy(y, model(x))\n",
    "\n",
    "    # End epoch\n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "test_fp = keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "                                  origin=test_url)\n",
    "\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    test_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name='species',\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels\n",
    "\n",
    "\n",
    "test_dataset = test_dataset.map(pack_features_vector)\n",
    "\n",
    "test_accuracy = keras.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in test_dataset:\n",
    "  logits = model(x)\n",
    "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "  test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))\n",
    "\n",
    "tf.stack([y,prediction],axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
