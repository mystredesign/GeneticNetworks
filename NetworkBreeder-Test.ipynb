{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: /Users/ian/.keras/datasets/iris_training.csv\n",
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n",
      "WARNING:tensorflow:From /Users/ian/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "OrderedDict([('sepal_length', <tf.Tensor: id=68, shape=(32,), dtype=float32, numpy=\n",
      "array([4.7, 6.3, 7.4, 4.9, 6.9, 5.8, 5.1, 6.7, 6.7, 5.1, 6.4, 4.9, 4.9,\n",
      "       5.8, 6.6, 4.8, 6.6, 4.9, 5. , 5. , 5. , 6. , 7.3, 6.8, 6.1, 5. ,\n",
      "       5.8, 6.1, 5.6, 7.9, 6.4, 6. ], dtype=float32)>), ('sepal_width', <tf.Tensor: id=69, shape=(32,), dtype=float32, numpy=\n",
      "array([3.2, 2.7, 2.8, 3. , 3.1, 2.7, 3.8, 3. , 3.1, 3.8, 2.8, 3.1, 3.1,\n",
      "       2.7, 2.9, 3. , 3. , 3.1, 3.6, 3.3, 3.5, 2.2, 2.9, 3. , 2.8, 2.3,\n",
      "       2.6, 2.9, 2.7, 3.8, 3.2, 3. ], dtype=float32)>), ('petal_length', <tf.Tensor: id=66, shape=(32,), dtype=float32, numpy=\n",
      "array([1.6, 4.9, 6.1, 1.4, 4.9, 4.1, 1.6, 5.2, 4.4, 1.5, 5.6, 1.5, 1.5,\n",
      "       5.1, 4.6, 1.4, 4.4, 1.5, 1.4, 1.4, 1.3, 5. , 6.3, 5.5, 4. , 3.3,\n",
      "       4. , 4.7, 4.2, 6.4, 5.3, 4.8], dtype=float32)>), ('petal_width', <tf.Tensor: id=67, shape=(32,), dtype=float32, numpy=\n",
      "array([0.2, 1.8, 1.9, 0.2, 1.5, 1. , 0.2, 2.3, 1.4, 0.3, 2.1, 0.1, 0.1,\n",
      "       1.9, 1.3, 0.1, 1.4, 0.1, 0.2, 0.2, 0.3, 1.5, 1.8, 2.1, 1.3, 1. ,\n",
      "       1.2, 1.4, 1.3, 2. , 2.3, 1.8], dtype=float32)>)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "train_dataset_fp = keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n",
    "# column order in CSV file\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)\n",
    "plt.scatter(features['petal_length'],\n",
    "            features['sepal_length'],\n",
    "            c=labels,\n",
    "            cmap='viridis')\n",
    "\n",
    "plt.xlabel(\"Petal length\")\n",
    "plt.ylabel(\"Sepal length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5.4 3.  4.5 1.5]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.1 2.6 5.6 1.4]], shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels\n",
    "train_dataset = train_dataset.map(pack_features_vector)\n",
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5043, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[ 3.4496427 , -0.7203656 ,  1.2507411 ],\n",
       "       [ 3.542039  , -0.683318  ,  1.342955  ],\n",
       "       [ 3.3160923 , -0.66011983,  1.276065  ],\n",
       "       [ 2.3425536 , -0.92035985,  1.0660728 ],\n",
       "       [ 4.010564  , -0.8338465 ,  1.5285674 ]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_models = 4\n",
    "models=[]\n",
    "for _ in range(n_models):\n",
    "    models.append(\n",
    "        tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(3)\n",
    "])\n",
    "    )\n",
    "predictions = models[0](features)\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 2.686091423034668\n"
     ]
    }
   ],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "\n",
    "l = loss(models[0], features, labels)\n",
    "print(\"Loss test: {}\".format(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "# print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "#                                           loss_value.numpy()))\n",
    "\n",
    "# optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "# print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "#                                           loss(model, features, labels).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def insert_layer_nonseq(model, layer_regex, insert_layer_factory,\n",
    "                        insert_layer_name=None, position='after'):\n",
    "\n",
    "    # Auxiliary dictionary to describe the network graph\n",
    "    network_dict = {'input_layers_of': {}, 'new_output_tensor_of': {}}\n",
    "\n",
    "    # Set the input layers of each layer\n",
    "    for layer in model.layers:\n",
    "        for node in layer.outbound_nodes:\n",
    "            layer_name = node.outbound_layer.name\n",
    "            if layer_name not in network_dict['input_layers_of']:\n",
    "                network_dict['input_layers_of'].update(\n",
    "                        {layer_name: [layer.name]})\n",
    "            else:\n",
    "                network_dict['input_layers_of'][layer_name].append(layer.name)\n",
    "\n",
    "    # Set the output tensor of the input layer\n",
    "    network_dict['new_output_tensor_of'].update(\n",
    "            {model.layers[0].name: model.input})\n",
    "\n",
    "    # Iterate over all layers after the input\n",
    "    for layer in model.layers[1:]:\n",
    "\n",
    "        # Determine input tensors\n",
    "        layer_input = [network_dict['new_output_tensor_of'][layer_aux] \n",
    "                for layer_aux in network_dict['input_layers_of'][layer.name]]\n",
    "        if len(layer_input) == 1:\n",
    "            layer_input = layer_input[0]\n",
    "\n",
    "        # Insert layer if name matches the regular expression\n",
    "        if re.match(layer_regex, layer.name):\n",
    "            if position == 'replace':\n",
    "                x = layer_input\n",
    "            elif position == 'after':\n",
    "                x = layer(layer_input)\n",
    "            elif position == 'before':\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError('position must be: before, after or replace')\n",
    "\n",
    "            new_layer = insert_layer_factory\n",
    "            if insert_layer_name:\n",
    "                new_layer.name = insert_layer_name\n",
    "            else:\n",
    "                new_layer.name = '{}_{}'.format(layer.name, \n",
    "                                                new_layer.name)\n",
    "            x = new_layer(x)\n",
    "            print('Layer {} inserted after layer {}'.format(new_layer.name,\n",
    "                                                            layer.name))\n",
    "            if position == 'before':\n",
    "                x = layer(x)\n",
    "        else:\n",
    "            x = layer(layer_input)\n",
    "\n",
    "        # Set new output tensor (the original one, or the one of the inserted\n",
    "        # layer)\n",
    "        network_dict['new_output_tensor_of'].update({layer.name: x})\n",
    "\n",
    "    return Model(inputs=model.inputs, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2255\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2d0c232f64ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                             insert_layer_name=None, position='replace')\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_insert_layer_nonseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-2d0c232f64ff>\u001b[0m in \u001b[0;36mtest_insert_layer_nonseq\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     insert_layer_nonseq(model1, regex, model2.layers[0],\n\u001b[0;32m---> 15\u001b[0;31m                             insert_layer_name=None, position='replace')\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtest_insert_layer_nonseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6ebfbb846f5d>\u001b[0m in \u001b[0;36minsert_layer_nonseq\u001b[0;34m(model, layer_regex, insert_layer_factory, insert_layer_name, position)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 new_layer.name = '{}_{}'.format(layer.name, \n\u001b[0;32m---> 49\u001b[0;31m                                                 new_layer.name)\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             print('Layer {} inserted after layer {}'.format(new_layer.name,\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2259\u001b[0m             ('Can\\'t set the attribute \"{}\", likely because it conflicts with '\n\u001b[1;32m   2260\u001b[0m              \u001b[0;34m'an existing read-only @property of the object. Please choose a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m              'different name.').format(name))\n\u001b[0m\u001b[1;32m   2262\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
     ]
    }
   ],
   "source": [
    "def test_insert_layer_nonseq():\n",
    "    model1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    model2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "            tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    regex = model1.layers[0].outbound_nodes[0].output_tensors.name\n",
    "    regex = model1.layers[1].outbound_nodes[0].inbound_layers.name\n",
    "    insert_layer_naonseq(model1, regex, model2.layers[0],\n",
    "                            insert_layer_name=None, position='replace')\n",
    "    \n",
    "test_insert_layer_nonseq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model source was copied into model target\n",
      "model source was copied into model target\n"
     ]
    }
   ],
   "source": [
    "# tested in Keras 1.x\n",
    "def copy_weights2model(w_source,target_model,certain_layer=\"\"):\n",
    "    l_nm=0\n",
    "    for layer in target_model.layers:\n",
    "        w_target=layer.get_weights()\n",
    "        if len(w_target)>0:\n",
    "            wk0=[w_source[2*l_nm],w_source[2*l_nm+1]]\n",
    "            layer.set_weights(wk0)\n",
    "            l_nm+=1\n",
    "            if layer.name==certain_layer:\n",
    "                break    \n",
    "\n",
    "                # copy weights from one model to another model    \n",
    "# tested in Keras 1.x    \n",
    "def copyModel2Model(model_source,model_target, up_to_certain_layer=\"\"):        \n",
    "    for l_tg,l_sr in zip(model_target.layers, model_source.layers):\n",
    "        wk0=l_sr.get_weights()\n",
    "        l_tg.set_weights(wk0)\n",
    "        if l_tg.name==up_to_certain_layer:\n",
    "            print('break')\n",
    "            break\n",
    "    print(\"model source was copied into model target\") \n",
    "copyModel2Model(models[0],models[1],\"dense_33\")\n",
    "\n",
    "# def breed_models(model_source, model_target, certain_layer):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_clone(model, input_tensors):\n",
    "    return tf.keras.models.clone_model(\n",
    "        model,\n",
    "        input_tensors=None,\n",
    "        clone_function=None\n",
    "    )\n",
    "\n",
    "def breed_models(model_source1, model_source2, layer_list=list(), prob_select_2=list(), input_tensors=None):\n",
    "\n",
    "    if not isinstance(prob_select_2, list) :\n",
    "        prob_select_2 = [prob_select_2]*len(layer_list)\n",
    "    model_target = model_clone(model_source1, input_tensors)\n",
    "    for l_tg,l_sr, prob in zip(model_target.layers, model_source2.layers, prob_select_2):\n",
    "\n",
    "        if l_tg.name in layer_list:\n",
    "            roll = np.random.rand()\n",
    "            if roll < prob:\n",
    "                wk0 = l_sr.get_weights()\n",
    "                l_tg.set_weights(wk0)\n",
    "\n",
    "    return model_target\n",
    "\n",
    "def test_breed_models():\n",
    "    n_models = 2\n",
    "    models=[]\n",
    "    for _ in range(n_models):\n",
    "        models.append(\n",
    "                tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "                tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Dense(3)\n",
    "            ])\n",
    "        )\n",
    "    model_new = breed_models(models[0],models[1], models[0].layers[0].name, 1)\n",
    "    assert(np.all((np.squeeze(models[1].layers[0].get_weights()[0]-model_new.layers[0].get_weights()[0])) == 0))\n",
    "    model_new = breed_models(models[0],models[1], models[1].layers[0].name, 0)\n",
    "    assert(np.all((np.squeeze(models[0].layers[0].get_weights()[0]-model_new.layers[0].get_weights()[0])) != 0))\n",
    "    \n",
    "    \n",
    "test_breed_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_conv_model_layer(model_source1, model_source2, layer_name,  prob_select_2=list(), \n",
    "                           input_tensors=None, \n",
    "                     ):\n",
    "    if not isinstance(prob_select_2, list) :\n",
    "        prob_select_2 = [prob_select_2]*len(layer_list)\n",
    "    model_target = model_clone(model_source1, input_tensors)\n",
    "    for l_tg,l_sr, prob in zip(model_target.layers, model_source2.layers, prob_select_2):\n",
    "        if l_tg.name in name:\n",
    "            roll = np.random.rand()\n",
    "            if roll < prob:\n",
    "                wk0 = l_sr.get_weights()\n",
    "                l_tg.set_weights(wk0)\n",
    "    \n",
    "    \n",
    "def test_breed_conv_models():\n",
    "    n_models = 2\n",
    "    models = []\n",
    "    for _ in range(n_models):\n",
    "        model =  tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        models.append(model)\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(52, 52, 3)))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2= tf.keras.Sequential()\n",
    "model2.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(52, 52, 3)))\n",
    "model2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model2.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12542, shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[-0.10087781,  0.0863834 , -0.01015307],\n",
       "        [ 0.02318041, -0.06305347, -0.03850353],\n",
       "        [-0.06927785,  0.12640204,  0.10435036]],\n",
       "\n",
       "       [[ 0.02720787,  0.09027302,  0.06989743],\n",
       "        [ 0.10577516, -0.10343836, -0.13326721],\n",
       "        [ 0.07208455,  0.0445036 ,  0.09387802]],\n",
       "\n",
       "       [[-0.06017017, -0.00910491, -0.0014572 ],\n",
       "        [ 0.11111504,  0.01833007, -0.0326406 ],\n",
       "        [-0.10435638, -0.02147277, -0.06814527]]], dtype=float32)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layers[0].weights[0].assign(model.layers[0].weights[0])\n",
    "model2.layers[0].weights[0][:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def breed_convolution_layer_weights(model1_layer, model2_layer, prob_choose_2=list()):\n",
    "    assert(model1_layer.weights[0].shape == model2_layer.weights[0].shape)\n",
    "    assert(model1_layer.weights[1].shape == model2_layer.weights[1].shape)\n",
    "\n",
    "    n_filters = model2_layer.weights[0].get_shape()[-1]\n",
    "    \n",
    "    if not isinstance(prob_choose_2, list):\n",
    "        prob_list = []\n",
    "        for _ in range(n_filters):\n",
    "            prob_list.append(prob_choose_2)\n",
    "    else:\n",
    "        prob_list = prob_choose_2\n",
    "    assert(n_filters == len(prob_list))\n",
    "    output_list = []\n",
    "    roll = 0\n",
    "\n",
    "    output_biases = []\n",
    "    for step_index, prob in enumerate(prob_list):\n",
    "        if roll < prob:\n",
    "            output_list.append(model2_layer.weights[0][:,:,:,step_index])\n",
    "            output_biases.append(model2_layer.weights[1][step_index])            \n",
    "        else:\n",
    "            output_list.append(model1.layer.weights[0][:,:,:,step_index])\n",
    "            output_biases.append(model1.layer.weights[1][step_index])\n",
    "\n",
    "    return tf.stack(output_list), tf.stack(output_biases)\n",
    "\n",
    "w, b = breed_convolution_layer_weights(model.layers[0], model2.layers[0], prob_choose_2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 3, 3, 3])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 32])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers[0].weights[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_convolution_layer(model1_layer, model2_layer, model_tg_layer, prob=list()):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_shape = model2.layers[0].weights[0].get_shape()\n",
    "tensor_shape\n",
    "output_list = []\n",
    "prob = 1;\n",
    "roll = 0\n",
    "output_biases = []\n",
    "for step_index in range(tensor_shape[-1]):\n",
    "    if roll < prob:\n",
    "        output_list.append(model2.layers[0].weights[0][:,:,:,step_index])\n",
    "        output_biases.append(model2.layers[0].weights[1][step_index])\n",
    "\n",
    "outputs = tf.stack(output_list)\n",
    "output_biases = tf.stack(output_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13553, shape=(32,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'conv2d_21/bias:0' shape=(32,) dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers[0].weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "                                  origin=test_url)\n",
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    test_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name='species',\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_dataset = test_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_22'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0 Epoch 000: Loss: 0.137, Accuracy: 96.667%\n",
      "Model: 0 Epoch 000: Accuracy: 96.667%\n",
      "Model: 1 Epoch 000: Loss: 0.130, Accuracy: 97.500%\n",
      "Model: 1 Epoch 000: Accuracy: 96.667%\n",
      "Model: 2 Epoch 000: Loss: 0.128, Accuracy: 97.778%\n",
      "Model: 2 Epoch 000: Accuracy: 96.667%\n",
      "Model: 3 Epoch 000: Loss: 0.124, Accuracy: 97.917%\n",
      "Model: 3 Epoch 000: Accuracy: 95.833%\n",
      "Model: 0 Epoch 050: Loss: 0.123, Accuracy: 98.333%\n",
      "Model: 0 Epoch 050: Accuracy: 96.667%\n",
      "Model: 1 Epoch 050: Loss: 0.118, Accuracy: 97.917%\n",
      "Model: 1 Epoch 050: Accuracy: 96.667%\n",
      "Model: 2 Epoch 050: Loss: 0.113, Accuracy: 98.056%\n",
      "Model: 2 Epoch 050: Accuracy: 96.667%\n",
      "Model: 3 Epoch 050: Loss: 0.110, Accuracy: 97.917%\n",
      "Model: 3 Epoch 050: Accuracy: 95.833%\n",
      "Model: 0 Epoch 100: Loss: 0.114, Accuracy: 97.500%\n",
      "Model: 0 Epoch 100: Accuracy: 96.667%\n",
      "Model: 1 Epoch 100: Loss: 0.114, Accuracy: 97.500%\n",
      "Model: 1 Epoch 100: Accuracy: 96.667%\n",
      "Model: 2 Epoch 100: Loss: 0.107, Accuracy: 97.778%\n",
      "Model: 2 Epoch 100: Accuracy: 96.667%\n",
      "Model: 3 Epoch 100: Loss: 0.102, Accuracy: 97.708%\n",
      "Model: 3 Epoch 100: Accuracy: 96.667%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2d0f8463b075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mepoch_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m   2716\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m       \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2718\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/tf2.0/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[0;34m(value, bias, data_format, name)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BiasAdd\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         data_format)\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "test_accuracy_results = []\n",
    "num_epochs = 201\n",
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    epoch_test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "    # Training loop - using batches of 32\n",
    "    for (model_n, model) in enumerate(models):\n",
    "\n",
    "        for x, y in train_dataset:\n",
    "        # Optimize the model\n",
    "            loss_value, grads = grad(model, x, y)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Track progress\n",
    "            epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "            # Compare predicted label to actual label\n",
    "            epoch_accuracy(y, model(x))\n",
    "\n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Model: {} Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(model_n, epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n",
    "\n",
    "        for (x, y) in test_dataset:\n",
    "            logits = model(x)\n",
    "            prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "            epoch_test_accuracy(y, model(x))\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Model: {} Epoch {:03d}: Accuracy: {:.3%}\".format(model_n, epoch,\n",
    "                                                                epoch_test_accuracy.result()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
    "                                  origin=test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    test_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name='species',\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "test_dataset = test_dataset.map(pack_features_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "for (x, y) in test_dataset:\n",
    "  logits = model(x)\n",
    "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "  test_accuracy(prediction, y)\n",
    "\n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 prediction: Iris setosa (97.4%)\n",
      "Example 1 prediction: Iris versicolor (91.7%)\n",
      "Example 2 prediction: Iris virginica (75.0%)\n"
     ]
    }
   ],
   "source": [
    "predict_dataset = tf.convert_to_tensor([\n",
    "    [5.1, 3.3, 1.7, 0.5,],\n",
    "    [5.9, 3.0, 4.2, 1.5,],\n",
    "    [6.9, 3.1, 5.4, 2.1]\n",
    "])\n",
    "\n",
    "predictions = model(predict_dataset)\n",
    "\n",
    "for i, logits in enumerate(predictions):\n",
    "  class_idx = tf.argmax(logits).numpy()\n",
    "  p = tf.nn.softmax(logits)[class_idx]\n",
    "  name = class_names[class_idx]\n",
    "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
